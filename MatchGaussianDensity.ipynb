{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb5798",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "pip install git+https://github.com/davidbau/baukit > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9711ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import show, Range, Numberbox, PlotWidget, set_requires_grad\n",
    "import torch, numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638ddf3",
   "metadata": {},
   "source": [
    "# Generative Modeling: the Classical Density Approach\n",
    "\n",
    "To make a generative **density** model, you start with a set of data points, like the following six 2D points $\\{x_i\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f98c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([[-0.2997,  0.7500,  2.4024, -3.3377, -1.3939, 1.2348],\n",
    "                     [ 0.2965,  0.1307, -1.5569,  1.3849,  1.0405, 1.1438]])\n",
    "def draw_data(fig, data, size=30):\n",
    "    [ax] = fig.axes\n",
    "    ax.scatter(data[0,:], data[1,:], s=size, color='red')\n",
    "    \n",
    "PlotWidget(draw_data, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7b137",
   "metadata": {},
   "source": [
    "And then you define a family of **probability density** functions to fit the data.  Here we use a 2d multivariate Gaussian model $\\mathcal{N}(\\Sigma; \\mu)$ which defined as:\n",
    "\n",
    "$$\n",
    "P(x) = \\frac{\\exp\\left(-\\frac{1}{2}(x - \\mu)^{T}\\Sigma^{-1}(x - \\mu)\\right)}{\\sqrt{(2 \\pi)^{d} \\det{\\Sigma}}} \n",
    "$$\n",
    "\n",
    "Despite the length of the formula, the multivariate Gaussian is very simple and is just an ellipsoid-shaped mound of probability density as below.\n",
    "\n",
    "It is parameterized by a matrix $\\Sigma$ and a vector $\\mu$.  If you re-run the cell, different parameters will be chosen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_density(fig, Sigma, Mean):\n",
    "    [ax] = fig.axes\n",
    "    for size in [0.668, 1.01, 1.35, 1.79]:\n",
    "        angle = torch.linspace(0, 6.3, 100)\n",
    "        circle = torch.stack([angle.sin(), angle.cos()])\n",
    "        ellipse = torch.mm(Sigma, circle) * size + Mean[:,None]\n",
    "        ax.plot(ellipse[0,:], ellipse[1,:], color='skyblue')\n",
    "PlotWidget(draw_density, Sigma=torch.randn(2, 2), Mean=torch.randn(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sample(fig, Sigma, Mean):\n",
    "    [ax] = fig.axes\n",
    "    z = torch.tensor(numpy.random.RandomState(2).randn(2, 500)).float()\n",
    "    x = Sigma @ z + Mean[:, None]\n",
    "    ax.scatter(x[0,:], x[1,:], s=20, color='slateblue')\n",
    "PlotWidget(draw_sample, Sigma=torch.randn(2, 2), Mean=torch.randn(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5233834",
   "metadata": {},
   "source": [
    "Then to **train** our generative model, we find the parameters $\\Sigma$ and $\\mu$ that make the observed data most likely. In other words, the predicted probabilities of the observed data should be the highest.\n",
    "\n",
    "Since each data item $x_i$ is independent, the probability of the whole data set is the product of the probabilities of each one.  We usually tag the negative log of these so we can just add them up.  For our Gaussian model, this negative log likelihood (NLL) for $\\{x_i\\}$ is:\n",
    "$$\n",
    "- \\log P[\\{x_i\\}] = - \\log \\prod_i P[x_i] = -\\sum_i \\log P[x_i] = \\sum_i \\left ( (x_i - \\mu)^T\\Sigma^{-1}(x_i - \\mu)  +  \\frac{1}{2} \\log \\det{\\Sigma} + \\frac{d}{2} \\log (2 \\pi) \\right )\n",
    "$$\n",
    "\n",
    "Again, seems like a lot of math, but it's just one line of code.  Below we define a function to compute the NLL over a bunch of data and graph it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f556f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gaussian_nll(x, Sigma, Mean):\n",
    "    x2 = x - Mean[:,None]\n",
    "    return (x2 * (torch.inverse(Sigma) @ x2)).sum(dim=0) + 0.5 * torch.logdet(Sigma) + math.log(math.pi * 2)\n",
    "\n",
    "def draw_negative_log_likelihood(fig, A=1.0, B=0.0, C=1.0, X=0.0, Y=0.0, title='Gaussian', sample=False):\n",
    "    [ax] = fig.axes\n",
    "    ax.clear(); ax.set_aspect('equal')\n",
    "    ax.set_xlim(-5, 5); ax.set_ylim(-5, 5)\n",
    "    Sigma = torch.tensor([[A, B], [B, C]]).float()\n",
    "    Mean = torch.tensor([X, Y])\n",
    "    if sample:\n",
    "        draw_sample(fig, Sigma, Mean)\n",
    "    draw_data(fig, data)\n",
    "    draw_density(fig, Sigma, Mean)\n",
    "    nll = gaussian_nll(data, Sigma, Mean)\n",
    "    for i in range(data.shape[1]):\n",
    "        ax.annotate(f'{nll[i].item():.3f}', (data[0,i].item(), data[1,i].item()))\n",
    "    ax.set_title(f'Negative log likelihood of {data.shape[1]} data points: {nll.sum().item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ee669",
   "metadata": {},
   "source": [
    "In the user interface below, we let you control $\\Sigma$ and $\\mu$ parameters by hand by adjusting sliders for $A$, $B$, $C$, $X$, and $Y$:\n",
    "\n",
    "$$\n",
    "\\text{parameters } \\theta \\text{ are: } \\qquad\n",
    "\\Sigma = \\begin{bmatrix} A & B \\\\ B & C \\end{bmatrix}\n",
    "\\qquad\n",
    "\\mu = \\begin{bmatrix} X \\\\ Y \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e06da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = PlotWidget(draw_negative_log_likelihood, figsize=(8,8))\n",
    "show([[show.style(textAlign='right'), v,\n",
    "       show.style(flex=5), Range(value=plot.prop(v), min=-2.0, max=6.0, step=0.01),\n",
    "       show.style(width=50), Numberbox(value=plot.prop(v))]\n",
    "          for v in 'ABCXY'] +\n",
    "     [[plot]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358c9c9",
   "metadata": {},
   "source": [
    "Can you find a parameter setting that achieves NLL of less than 23?\n",
    "\n",
    "So this is the standard **density model** setting:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}